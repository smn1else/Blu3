# <img src="renderer/assets/icon.png" alt="Blu3 Logo" width="35"/> Asistente Shimeji con IntegraciÃ³n de IA Local (Ollama)

Una aplicaciÃ³n de asistente virtual con mascota de escritorio que utiliza inteligencia artificial local gracias a **Ollama**.

## âœ¨ CaracterÃ­sticas

* Mascota animada personalizable
* Reconocimiento de lenguaje natural en espaÃ±ol
* Respuestas impulsadas por IA local con Ollama
* SÃ­ntesis de voz (text-to-speech)
* Capacidad para abrir archivos y programas

## âš™ï¸ Requisitos Previos

Antes de ejecutar la aplicaciÃ³n, asegÃºrate de tener Ollama instalado:

1. Descarga e instala Ollama desde [ollama.ai](https://ollama.ai)
2. Descarga el modelo de IA que desees (por ejemplo, Mistral):

   ```bash
   ollama pull mistral
   ```
3. Verifica que Ollama estÃ© en ejecuciÃ³n antes de iniciar la app

## ğŸš€ InstalaciÃ³n

1. Clona este repositorio
2. Instala las dependencias:

   ```bash
   npm install
   ```
3. Inicia la aplicaciÃ³n:

   ```bash
   npm start
   ```

## ğŸ§  CÃ³mo Usarlo

* **Haz clic en la mascota** para activar el recuadro de mensajes
* **Escribe en espaÃ±ol** para interactuar con ella
* **ArrÃ¡strala** con el mouse para moverla por la pantalla
* **Escribe â€œabrir \[programa/archivo]â€** para ejecutar apps o archivos locales. Lista de [Comandos](https://github.com/smn1else/Blu3/blob/main/COMANDOS.md).

## ğŸ” Â¿CÃ³mo Funciona?

1. Utiliza un cuadro de texto donde se introduce tu mensaje
2. La entrada se envÃ­a a un modelo IA local mediante Ollama
3. El asistente responde con texto y voz

## ğŸ›  PersonalizaciÃ³n

Puedes cambiar el modelo de IA modificando el archivo `src/services/aiService.js`:

```javascript
const response = await axios.post('http://localhost:11434/api/generate', {
  model: 'mistral', // Cambia esto por el modelo que hayas descargado
  prompt: `Eres un asistente amigable llamado Blu3. Responde de manera breve y simpÃ¡tica en espaÃ±ol a: ${userInput}`,
  stream: false
});
```

## ğŸ§© SoluciÃ³n de Problemas

* Â¿No conecta con Ollama? AsegÃºrate de que estÃ© en ejecuciÃ³n
* Â¿Las respuestas son lentas? Prueba con un modelo mÃ¡s ligero

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia [MIT](https://github.com/smn1else/Blu3/blob/main/LICENSE).
